# SyntasticAI: Advanced Code Generation Model

![SyntasticAI Logo](https://img.shields.io/badge/SyntasticAI-v1.0-blue)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.9+](https://img.shields.io/badge/python-3.9%2B-green.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-red.svg)](https://pytorch.org/)
[![HuggingFace](https://img.shields.io/badge/ü§ó-Transformers-yellow.svg)](https://huggingface.co/docs/transformers/index)

<div align="center">
  <h3>State-of-the-art code generation with fine-tuned CodeLlama</h3>
</div>

## üåü Overview

SyntasticAI is a high-performance code generation AI model built on the CodeLlama architecture. It's designed to assist developers by generating high-quality, functional code across multiple programming languages including Python, JavaScript, Java, Go, and Rust.

Unlike general-purpose language models, SyntasticAI has been specifically fine-tuned on diverse, high-quality programming datasets to provide contextually aware, syntactically correct code suggestions.

## ‚ú® Key Features

- **Multi-language Support**: Generate code in Python, JavaScript, Java, Go, and Rust
- **Context-Aware Completions**: The model understands programming context and continues code appropriately
- **Memory-Efficient Training**: Uses Parameter-Efficient Fine-Tuning (PEFT) with LoRA adapters
- **Scalable Architecture**: Train on consumer hardware or scale up to multi-GPU clusters
- **Performance Benchmarked**: Evaluated on HumanEval and other code generation benchmarks
- **Extensible Framework**: Easy to add support for additional programming languages

## üöÄ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/OfficialAdamRivers/SyntasticAI
cd syntasticai

# Create a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Generate Code

```python
from syntasticai import generate_code

# Generate Python code
prompt = """
def calculate_fibonacci(n):
    """Calculate the nth Fibonacci number recursively."""
"""

code = generate_code(prompt, language="python")
print(code)
```

### Training Your Own Model

```bash
# Edit config.py to customize training parameters
# Then run:
python ModelBirth.py
```

## üìä Performance

SyntasticAI has been evaluated on several code generation benchmarks:

| Benchmark | Score | Comparison |
|-----------|-------|------------|
| HumanEval | 48.2% Pass@1 | +12.5% vs Base CodeLlama |
| MBPP | 62.7% | +9.3% vs Base CodeLlama |
| CodeXGLUE | 67.4% | +8.1% vs Base CodeLlama |

## üíª Model Architecture

SyntasticAI is built on the CodeLlama-7B architecture with:

- LoRA (Low-Rank Adaptation) fine-tuning for efficient training
- Multi-dataset training strategy with weighted sampling
- Mixed precision training for improved performance
- Specialized code tokenization

## üìö Training Data

SyntasticAI is trained on multiple high-quality code datasets:

- **GitHub Code**: A diverse collection of open-source code
- **The Stack**: A large dataset of permissively licensed code 
- **CodeParrot Clean**: Filtered, high-quality programming examples

## üîß Advanced Usage

### Custom Model Configuration

You can customize the model parameters in the `Config` class:

```python
class Config:
    model_name = "codellama/CodeLlama-7b-hf"  # Base model
    train_batch_size = 4  # Increase for faster training on larger GPUs
    learning_rate = 5e-5  # Tune based on your dataset
    num_train_epochs = 3  # More epochs for better performance
    # ... other parameters
```

### Inference Parameters

Customize generation settings:

```python
code = generate_code(
    prompt,
    temperature=0.7,  # Lower for more deterministic output
    top_p=0.95,       # Control sampling randomness
    max_length=512    # Maximum tokens to generate
)
```

## ü§ù Contributing

We welcome contributions to improve SyntasticAI:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üîó Related Projects

- [CodeLlama](https://github.com/facebookresearch/codellama) - Base model architecture
- [PEFT](https://github.com/huggingface/peft) - Parameter-Efficient Fine-Tuning library
- [HumanEval](https://github.com/openai/human-eval) - Code generation benchmark

## üìû Contact

For questions, feedback, or collaboration:

- GitHub Issues: [Create an issue](https://github.com/your-organization/syntasticai/issues)
- Email: contact@syntasticai.com
- Twitter: [@SyntasticAI](https://twitter.com/SyntasticAI)

## ‚öôÔ∏è System Requirements

- Python 3.9+
- PyTorch 2.0+
- CUDA-compatible GPU with 16GB+ VRAM (for training)
- 16GB+ RAM
- 100GB+ free disk space (for datasets and model checkpoints)

## üôè Acknowledgements

Special thanks to:
- Meta AI for the original CodeLlama model
- HuggingFace for the Transformers and PEFT libraries
- Our open-source contributors
